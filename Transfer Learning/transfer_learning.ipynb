{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amirreza Hosseini </br> \n",
    "HW3-Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "کتاب خانه‌های مورد نظر را وارد می‌کنیم<br>\n",
    "این کتابخانه ها عبارتند از : \n",
    "\n",
    "\n",
    "*   numpy\n",
    "*   matplotlib\n",
    "*   `torch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Y2dqyxnr6psU"
   },
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "       # transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "      #  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "       # transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "       # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "#download mnist dataset \n",
    "data_dir = 'data/mnist'\n",
    "image_datasets = {x: datasets.MNIST(data_dir, train=x=='train', download=True, transform=data_transforms[x])\n",
    "                  \n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=128,\n",
    "                                             shuffle=True, num_workers=2)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ####\n",
    "\n",
    "<div dir=rtl>\n",
    "در این قسمت دیتاست گفته شده را دانلود کردیم(با استفاده از خود کتابخانه پایتورچ) و برای اینکه فرآیند خواندن دیتاست سریع تر و بهینه تر باشد از \n",
    "DataLoader\n",
    "استفاده کردیم.\n",
    "<br>\n",
    "\n",
    "همچنین با استفاده از data transform داده‌ها را تبدیل به اندازه مورد نظر تبدیل می‌کنیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#switch to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use **vgg16** to reduce the time and calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        #self.pre_layar = nn.Linear(in_features=1, out_features=3)\n",
    "        self.conv2d=nn.Conv2d(1, 3, 3,padding=1)\n",
    "       \n",
    "        self.backbone = models.vgg16(pretrained=True)\n",
    "        #self.backbone.modules[6] = nn.Linear(in_features=4096, out_features=2)\n",
    "        #self.fv1 = nn.Linear(in_features=2, out_features=2)\n",
    "        self.fv2 = nn.Linear(in_features=1000, out_features=10)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "       # print(x.size())\n",
    "        x=self.conv2d(x)\n",
    "        #print(x.size())\n",
    "       # x = self.pre_layar(x)\n",
    "        x = self.backbone(x)\n",
    "        #print(x.size())\n",
    "       # x = self.fv1(x)\n",
    "        x = self.fv2(x)\n",
    "        #print(x.size())\n",
    "       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "در کلاسی که تعریف می‌کنیم یک لایه قبل از شبکه\n",
    "vgg\n",
    "تعریف می‌کنیم تا بتوانیم کانال‌های رنگی سیاه سفید را به رنگی تبدیل کنیم زیرا میدانیم\n",
    "vgg\n",
    "تنها با عکس‌های رنگی کار می‌کند پس مجبوریم سایز ورودی را تغییر دهیم\n",
    "<div>\n",
    "<br>\n",
    "optimize function=SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**first scenario** </br>\n",
    "finetune: learning the whole model <br>\n",
    "(requires_grad) default value is TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give the data to the model\n",
    "model = MyModel()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "#model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train first scenario**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = train_model(model, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second scenario** <br>\n",
    "feature extraction: learning only the new layars and freeze others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        #self.pre_layar = nn.Linear(in_features=1, out_features=3)\n",
    "        self.conv2d=nn.Conv2d(1, 3, 3,padding=1)\n",
    "       \n",
    "        self.backbone = models.vgg16(pretrained=True)\n",
    "        #self.backbone.modules[6] = nn.Linear(in_features=4096, out_features=2)\n",
    "        #self.fv1 = nn.Linear(in_features=2, out_features=2)\n",
    "        self.fv2 = nn.Linear(in_features=1000, out_features=10)\n",
    "\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "       # print(x.size())\n",
    "        x=self.conv2d(x)\n",
    "        #print(x.size())\n",
    "       # x = self.pre_layar(x)\n",
    "        x = self.backbone(x)\n",
    "        #print(x.size())\n",
    "       # x = self.fv1(x)\n",
    "        x = self.fv2(x)\n",
    "        #print(x.size())\n",
    "       \n",
    "        return x\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=rtl>\n",
    "در سناریو دوم نیز تمام پارامتر‌های مدل اصلی را فیریز می‌کنیم و فقط لایه‌های اول و آخر را آپدیت می‌کنیم برای این کار از امکان\n",
    "param.requires_grad= False\n",
    "استفاده می‌کنیم\n",
    "<br>\n",
    "<div>\n",
    "optimize function=SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give the data to the model\n",
    "model = MyModel()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "#model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "#optimizer_conv = optim.Adam(model.fv1.parameters(), lr=0.001)\n",
    "#optimizer_conv = optim.Adam(model.fv2.parameters(), lr=0.001)\n",
    "optimizer_conv = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train the second scenario**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = train_model(model, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f56a879a86e4cb184598e0f1a037d80ac9bf804487d5cf89fe943b503a6b43f5"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
